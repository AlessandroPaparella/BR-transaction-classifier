{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testing.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlessandroPaparella/BR-transaction-classifier/blob/main/testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xyEFXP6KHl0"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvRhljQcKLoV"
      },
      "source": [
        "#Get access to gdrive space to import datasets...\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n440uOh7KNGf"
      },
      "source": [
        "#Import test set and weight for models\n",
        "!cp drive/MyDrive/test.csv ./test.csv\n",
        "!cp drive/MyDrive/class_epoch_6.h5 ./class_epoch_6.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiUwLcWgM3iW"
      },
      "source": [
        "#Dataset to 3d tensor converion ([Samples, Time, Features])\n",
        "#Sample: Just TX row\n",
        "#Time: Sequence of the Tx trace\n",
        "#Feature: value, type etc... of the single calls\n",
        "\n",
        "import json, ast, textwrap\n",
        "import numpy as np\n",
        "\n",
        "#Features len\n",
        "TYPE_LEN=1\n",
        "INPUT_LEN=32\n",
        "OUTPUT_LEN=32\n",
        "GAS_LEN=1\n",
        "GASUSED_LEN=1\n",
        "CALLS_LEN=1\n",
        "\n",
        "TOTAL_LEN=TYPE_LEN+INPUT_LEN+OUTPUT_LEN+GAS_LEN+GASUSED_LEN+CALLS_LEN\n",
        "\n",
        "#Max calls per sample\n",
        "MAX_CALLS=150\n",
        "\n",
        "calls = {\n",
        "    \"CALL\": 1,\n",
        "    \"STATICCALL\": 2,\n",
        "    \"DELEGATECALL\": 3,\n",
        "    \"CALLCODE\": 4,\n",
        "    \"CREATE\": 5,\n",
        "    \"SELFDESTRUCT\": 6\n",
        "}\n",
        "\n",
        "#Horizontal padding for time dimension\n",
        "def pad():\n",
        "  p=[]\n",
        "  for i in range(68):\n",
        "    p.append(0)\n",
        "  return p\n",
        "\n",
        "#Split a large hex number \"n\" (string format) into \"p\" 64bit token\n",
        "def split(n, p):\n",
        "  tokens = textwrap.wrap(n, 16)\n",
        "  for i in range(len(tokens)):\n",
        "    tokens[i]=str(\"0x\"+tokens[i])\n",
        "    tokens[i] = int(tokens[i], 0) % 2 ** 64\n",
        "    if i==p:\n",
        "      break\n",
        "  #pad to passed length \"p\"\n",
        "  if len(tokens)<p:\n",
        "    m = p-len(tokens)\n",
        "    for i in range(m):\n",
        "      tokens.append(0)\n",
        "  return tokens[:p]\n",
        "\n",
        "#Join array \"tok\" into \"row\"\n",
        "def insertInRow(tok, row):\n",
        "  for t in tok:\n",
        "    row.append(t)\n",
        "  return row\n",
        "\n",
        "total_data = []\n",
        "\n",
        "#Explore trace with DFS and put all calls into a 2d matrix (time x calls)\n",
        "def DFS(df):\n",
        "    global total_data\n",
        "    t = []\n",
        "    t.append(calls[df['type']])\n",
        "    t.append(int(df['gas'], 0) if \"gas\" in df else 0)\n",
        "    tok = split(df['input'][2:], INPUT_LEN) if \"input\" in df else split(\"0\", INPUT_LEN)\n",
        "    t = insertInRow(tok, t)\n",
        "    tok = split(df['output'][2:], OUTPUT_LEN) if \"output\" in df else split(\"0\", OUTPUT_LEN)\n",
        "    t = insertInRow(tok, t)\n",
        "    t.append(int(df['gasUsed'], 0) if \"output\" in df else 0)\n",
        "    #Bool flag that report if there are other nested calls or not\n",
        "    t.append(1 if \"calls\" in df else 0)\n",
        "    total_data.append(t)\n",
        "    if \"calls\" in df:\n",
        "        for d in df[\"calls\"]:\n",
        "          DFS(d)\n",
        "\n",
        "\n",
        "def calls_to_tensor(df):\n",
        "  examples=[]\n",
        "  for d in df.itertuples():\n",
        "    #Get txTrace column into a tree\n",
        "    txTrace=ast.literal_eval(d[1])\n",
        "    global total_data\n",
        "    total_data=[]\n",
        "    DFS(txTrace)\n",
        "    #Pad to MAX CALLS\n",
        "    i=len(total_data)\n",
        "    while i<150:\n",
        "      total_data.append(pad())\n",
        "      i+=1\n",
        "    examples.append(total_data[:150])\n",
        "  return tf.convert_to_tensor(np.array(examples), dtype=tf.uint64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2W0f4AlKR6I"
      },
      "source": [
        "#Define model for classification\n",
        "\n",
        "from keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input\n",
        "\n",
        "def create_model_class():\n",
        "  model = Sequential()\n",
        "  model.add(Input((150,TOTAL_LEN)))\n",
        "  model.add(LSTM(units=4096))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZrwYUbiMjPK"
      },
      "source": [
        "#Connect to cluster TPU and get strategy distribution\n",
        "\n",
        "import os\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noLV1lNnMnTC"
      },
      "source": [
        "#Create model, compile and load weights from previous training\n",
        "with strategy.scope():\n",
        "    classification_model = create_model_class()\n",
        "    classification_model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), metrics=[tf.keras.metrics.AUC()])\n",
        "    classification_model.load_weights(\"class_epoch_6.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLgXn5Z4NI5s"
      },
      "source": [
        "def load_data(Train_df,idx,\n",
        "              batch_size):\n",
        "    df = pd.read_csv(\n",
        "                  Train_df, skiprows=idx*batch_size,\n",
        "                  nrows=batch_size)\n",
        "    df.columns = ['txTrace']\n",
        "    x = calls_to_tensor(df)\n",
        "    return (x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtydC6a1mSdu"
      },
      "source": [
        "test = pd.read_csv(\"test.csv\")\n",
        "l_test = len(test)\n",
        "test_steps = int(np.ceil(l_test/2048))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOa_wVxdlIVr"
      },
      "source": [
        "binaryPreds=np.array([])\n",
        "for i in range(test_steps):\n",
        "  x = load_data(\"test.csv\", i, 2048)\n",
        "  y=classification_model.predict_on_batch(x).reshape(1,-1)\n",
        "  binaryPreds = np.append(binaryPreds, y[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH7TfxPJ8pr_"
      },
      "source": [
        "# Writing result for submission\n",
        "\"\"\"\n",
        "import csv\n",
        "submission = csv.writer(open('submission.csv', 'w', encoding='UTF8'))\n",
        "for x, y in zip(binaryPreds, regressionPreds):\n",
        "  submission.writerow([x, y])\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}